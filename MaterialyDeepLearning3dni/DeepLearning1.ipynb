{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metoda spadku gradientu (gradient descent)\n",
    "\n",
    "Mamy problem optymalizacyjny: szukamy parametru $\\theta$, dla którego funkcja $f(\\theta)$ przyjmuje wartość najmniejszą.\n",
    "\n",
    "Algorytm:\n",
    "\n",
    "Iteracyjnie poprawiamy wartość parametru według wzoru:\n",
    "\n",
    "$$\\theta_{new} = \\theta_{old} - learning\\_rate * \\frac{df}{d\\theta}$$\n",
    "\n",
    "Dlaczego tak?\n",
    "- gdy funkcja dla danego $\\theta$ jest rosnąca, to pochodna jest dodatnia, więc przesumamy się w lewo,\n",
    "- gdy funkcja dla danego $\\theta$ jest malejąca, to pochodna jest ujemna, więc przesumamy się w prawo.\n",
    "\n",
    "W skrócie: sprawdzamy w którą stronę funkcja maleje i tam się przesywamy - tym dalej im nachylenie większe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def f(x):\n",
    "    return(x**2 - 6*x + 12)\n",
    "    \n",
    "def grad_f(x):\n",
    "    return(2*x - 6)\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "def visualise_gradient_decsent(f=f,grad_f=grad_f,theta = -2, learning_rate=0.8, sec=3, x = np.linspace(-5,11,100)):\n",
    "\n",
    "    \"\"\"\n",
    "    Funkcja wizualizujaca optymalizacje metoda spadku gradient.\n",
    "    \n",
    "    f - definicja funkcji, ktora chcemy zoptymalizowac\n",
    "    grad_f - definicja jej pochodnej\n",
    "    theta - punkt startowy\n",
    "    learning_rate - wspolczynnik uczenia\n",
    "    sec - dlugosc przerwy pomiedzy wyswietlaniem kolejnych elementow w sekundach\n",
    "    x - przedzial na ktorym wizualizujemy dzialanie metody\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    y = f(x)\n",
    "    \n",
    "    for i in range(100):\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.plot(x,y,c=\"blue\")\n",
    "        plt.scatter(theta,0,s=60)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(sec)\n",
    "\n",
    "        plt.vlines(x=theta,ymin=0,ymax=f(theta))\n",
    "\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(sec)\n",
    "\n",
    "        theta_new = theta - learning_rate*grad_f(theta)\n",
    "\n",
    "\n",
    "        plt.arrow(theta, f(theta), 2, 2*grad_f(theta), head_width = 0.3,head_length = 0.3 )\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(sec)\n",
    "\n",
    "\n",
    "        plt.text(-1,40,\"grad = %.3f\" % grad_f(theta), fontsize=20)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(sec)\n",
    "\n",
    "        plt.text(-2,30,\"step = -1 *  %.2f * %.2f = \" % (learning_rate,grad_f(theta)), fontsize=20)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(sec)\n",
    "\n",
    "        plt.text(-2,30,\"step = -1 *  %.2f * %.2f = %.2f\" % (learning_rate,grad_f(theta), -learning_rate*grad_f(theta)), fontsize=20)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(sec)\n",
    "\n",
    "\n",
    "\n",
    "        delta = theta_new - theta\n",
    "\n",
    "        plt.text(min(theta,theta_new),3,\"step = %.3f\" % ( -learning_rate*grad_f(theta)), fontsize=20)\n",
    "        plt.arrow(theta, 0, 0.9*delta, 0, head_width = 1,head_length = np.abs(0.1*delta),color=\"red\" )\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        #plt.annotate('', xy=(theta, 10), xytext=(theta_new, 10),\n",
    "        #                   arrowprops={'arrowstyle': '->', 'color': 'r', 'lw': 1},\n",
    "        #                   va='center', ha='center')\n",
    "        theta = theta_new\n",
    "\n",
    "        plt.vlines(x=theta,ymin=0,ymax=f(theta))\n",
    "        #plt.show()\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c0121abdc292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualise_gradient_decsent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-16d9001b19e7>\u001b[0m in \u001b[0;36mvisualise_gradient_decsent\u001b[0;34m(f, grad_f, theta, learning_rate, sec, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2245\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1143\u001b[0;31m                 renderer, self, dsu, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2407\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2409\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2411\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_gc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_gc_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_snap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_snap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "visualise_gradient_decsent(learning_rate=0.8,sec=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualise_gradient_decsent(sec=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualise_gradient_decsent(learning_rate=1,sec=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f1e0a0133d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvisualise_gradient_decsent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-16d9001b19e7>\u001b[0m in \u001b[0;36mvisualise_gradient_decsent\u001b[0;34m(f, grad_f, theta, learning_rate, sec, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m#plt.annotate('', xy=(theta, 10), xytext=(theta_new, 10),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2193\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1143\u001b[0;31m                 renderer, self, dsu, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2407\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2409\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2411\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    800\u001b[0m                     textrenderer.draw_text(gc, x, y, clean_line,\n\u001b[1;32m    801\u001b[0m                                            \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                                            ismath=ismath, mtext=mtext)\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kodolamacz/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw_text\u001b[0;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# We pass '0' for angle here, since it will be rotated (in raster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;31m# space) in the following call to draw_text_image).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_glyphs_to_bitmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mantialiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.antialiased'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m64.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return(0.5*(x**4 - x**3 - 6*x**2 + 30) )\n",
    "\n",
    "def grad_f(x):\n",
    "    return(0.5*(4*x**3 - 3*x**2 - 12*x))\n",
    "\n",
    "visualise_gradient_decsent(f,grad_f,theta=-3,learning_rate=0.1,x=np.linspace(-4,4,300),sec=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAJCCAYAAAAY3mkcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPtqpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35b0095128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6950fe62de62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualise_gradient_decsent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-16d9001b19e7>\u001b[0m in \u001b[0;36mvisualise_gradient_decsent\u001b[0;34m(f, grad_f, theta, learning_rate, sec, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "visualise_gradient_decsent(f,grad_f,theta=-3,learning_rate=0.1,x=np.linspace(-4,4,300),sec=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uczenie odbywa się w \"epokach\" - jedna epoka to aktualizaja wartosci parametru na podstawie całego zbioru obserwacji.\n",
    "\n",
    "## Gradient decsent:\n",
    "$$ Cost(\\theta) = \\frac{1}{n} \\sum\\limits_{i=1}^n f(x_i,y_i,\\theta)$$\n",
    "$$\\theta_k = \\theta_k - learning\\_rate * \\frac{dCost}{d\\theta_k}$$\n",
    "\n",
    "## Stochastic gradient decsent - SGD:\n",
    "\n",
    "\n",
    "$$ Cost(\\theta) = \\frac{1}{r} \\sum\\limits_{i \\in \\{ i_1, ..., i_r \\}} f(x_i,y_i,\\theta),$$ $$ \\ \\ \\text{gdzie} \\ \\ \\{ i_1, ..., i_r \\} - \\text{losowy podzbiór obserwacji}$$\n",
    "$$\\theta_i = \\theta_i - learning\\_rate * \\frac{df}{d\\theta_j}$$\n",
    "i powtarzamy to wielokrotnie tak, żeby każda obserwacja została wykorzystana jeden raz - w praktyce mieszamy losowo kolejność obserwacji i bierzemy kolejne podzbiory - np. dla \"batcha\" wielkości 10, uczymy kolejno na obserwacjach od 1 do 10, od 11 do 20, itd.. Przejście po całych danych to jedna *epoka*.\n",
    "\n",
    "SGD jest domyślnym algorytmem uczenia sieci neuronowych wszelkiego rodzaju."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Grafika/neuron.jpg\" width=\"500\">\n",
    "\n",
    "Źródło: https://cdn-images-1.medium.com/max/1600/0*l4ohhbrwQ5MGvmGc.jpg\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"Grafika/perceptron.gif\" width=\"400\">\n",
    "Źródło: http://blog.zabarauskas.com/img/perceptron.gif\n",
    "\n",
    "$\\sigma(\\cdot)$ - funkcja aktywacji\n",
    "\n",
    "## $\\sigma(x) = \\frac{1}{1+\\exp{(x)}}$\n",
    "\n",
    "W praktyce popularne są trzy funkcje aktywacji:\n",
    "\n",
    "- sigmoid\n",
    "- tangens hiperboliczny\n",
    "- RELU: $relu(x) = \\max{(x,0)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron jako klasyfikator:  Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "   # setup marker generator and color map\n",
    "   markers = ('s', 'x', 'o', '^', 'v')\n",
    "   colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "   cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "   # plot the decision surface\n",
    "   x1_min, x1_max = X[:,  0].min() - 1, X[:, 0].max() + 1\n",
    "   x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "   xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "   np.arange(x2_min, x2_max, resolution))\n",
    "   Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "   Z = Z.reshape(xx1.shape)\n",
    "   plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "   plt.xlim(xx1.min(), xx1.max())\n",
    "   plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "   # plot class samples\n",
    "   for idx, cl in enumerate(np.unique(y)):\n",
    "      plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "      alpha=0.8, c=cmap(idx),\n",
    "      marker=markers[idx], label=cl)\n",
    "\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, eta=0.1, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, X, y):\n",
    "\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.w_[0] = -50\n",
    "        self.w_[1] = 10\n",
    "        self.w_[2] = 1\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            plt.figure(figsize=(5,5))\n",
    "        \n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                \n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] +=  update * xi\n",
    "                self.w_[0] +=  update\n",
    "                errors += int(update != 0.0)\n",
    "                \n",
    "            plt.scatter(X[:,0],X[:,1],c=y)\n",
    "            plt.plot(np.linspace(4,7,100),-1 * (self.w_[0]+self.w_[1]*np.linspace(4,7,100))/self.w_[2])\n",
    "            plt.title('Perceptron')\n",
    "            plt.xlabel('sepal length [cm]')\n",
    "            plt.ylabel('petal length [cm]')\n",
    "            plt.xlim(4,7)\n",
    "            plt.ylim(-1,6)\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            time.sleep(1)\n",
    "\n",
    "            self.errors_.append(errors)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wizualizacja procesu uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAFNCAYAAAC5YlyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ff5485320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x7f4ff66baef0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Dane/iris.data', header=None)\n",
    "\n",
    "# setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# sepal length and petal length\n",
    "X = df.iloc[0:100, [0,2]].values\n",
    "\n",
    "ppn = Perceptron(epochs=20, eta=0.15)\n",
    "ppn.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Wielowarstwowa sieć neuronowa\n",
    "\n",
    "(*Multilayer perceptron*, *feedforward neural network*)\n",
    "\n",
    "\n",
    "<img src=\"Grafika/MLP.jpg\" width=\"700\">\n",
    "Źródło: https://www.intechopen.com/source/html/39071/media/f2.jpg\n",
    "\n",
    "\n",
    "**Uwaga:** \"Input layer\" pomimo tego, że ma w nazwie słowo \"warstwa\", to tak naprawdę to nie jest żadna warstwa sieci... To są po prostu dane wejściowe... Niestety przyjęło się literaturze nazywanie tego w ten sposób, co jest mylące :(\n",
    "\n",
    "\n",
    "Sieci uczy sie metodą spadku gradientu (pewnymi wariantami tej metody). Uczenie wykorzystuje algorytm **propagacji wsteczej** (https://en.wikipedia.org/wiki/Backpropagation).\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Uwaga!** Sieci neuronowe absolutnie zawsze wymagają zestandaryzowanych danych! Niezależnie od tego czy wykorzystujemy regularyzację czy nie i niezależnie od typu sieci!\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Wizualizacja obszarów decyzyjnych w zależności od liczby neuronów\n",
    "\n",
    "### (sieć jednowarstwowa)\n",
    "\n",
    "<img src=\"Grafika/nn-from-scratch-hidden-layer-varying-655x1024.png\" width=\"700\">\n",
    "Źródło: http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/nn-from-scratch-hidden-layer-varying-655x1024.png\n",
    "\n",
    "<br>\n",
    "\n",
    "### Fakt matematyczny: jednowarstwową siecią możemy otrzymać dowolny kształt. \n",
    "\n",
    "Co z tego wynika? To, że (teoretycznie) zawsze wystarczy sieć jednowarstwowa (odpowiednio duża). W praktyce rzeczywiście z reguły wystarcza jedna warstwa, ale mimo wszystko zawsze warto sprawdzić czy 2 (lub 3) nie zadziałają przypadkiem lepiej. Przy czym jeżeli dla dwóch wartsw jest gorzej, to nie ma sensu sprawdzać dla większej ilości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "0.3489583333333333\n",
      "Accuracy: 77.95% AUC:  0.8284353193773484\n",
      "Accuracy: 70.87% AUC:  0.6776704240472355\n",
      "Accuracy: 76.38% AUC:  0.8345410628019323\n",
      "Accuracy: 77.17% AUC:  0.8307165861513688\n",
      "Accuracy: 73.62% AUC:  0.7859634997316157\n",
      "Accuracy: 70.47% AUC:  0.7807971014492754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt('Dane/pima-indians-diabetes.data', delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "print(X.shape)\n",
    "print(np.mean(Y))\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "####\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "####\n",
    "\n",
    "\n",
    "models = [LogisticRegression(),\n",
    "          DecisionTreeClassifier(),\n",
    "          SVC(probability=True), \n",
    "          LinearDiscriminantAnalysis(), \n",
    "          QuadraticDiscriminantAnalysis(), \n",
    "          RandomForestClassifier()]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    predictions = np.round(y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0), \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy MLP w sklearnie zatrzymuje uczenie na podstawie tego co się dzieje w treningowym! Na to sobie można pozwolić,\n",
    "gdy pracujemy nad prostym problemem klasyfikacji, gdzie naszymi danymi jest tabelka, bo eksperymenty nie zajmują duzo czasu. Przy bardziej złożonych problemach, podchodzimy do tego inaczej!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.38% AUC:  0.823738593666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier((20,10))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:,1]\n",
    "predictions = y_pred.round()\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0), \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:48: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15060, 41)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy wyniki na surowych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=None, test_size=0.1, train_size=None),\n",
       "       error_score='accuracy',\n",
       "       estimator=MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.15, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'hidden_layer_sizes': [5, 10, 15, 30, 50, 100, 250, 500, 750, 1000, 2000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"hidden_layer_sizes\": [(5),(10),(15),(30),(50),(100),(250),(500),(750),(1000),(2000)]}\n",
    "\n",
    "nnet = MLPClassifier(activation=\"tanh\",early_stopping=True,validation_fraction=0.15,max_iter=1000)\n",
    "gs = GridSearchCV(cv=ShuffleSplit(n_splits=1,test_size=0.1),error_score=\"accuracy\",estimator=nnet,param_grid=params)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 2.01808119,  2.92763948,  1.95901299,  5.88557649,  4.03089452,\n",
       "         8.17512083, 11.45967126, 41.7235229 , 36.73673391, 92.48016906,\n",
       "        59.6756742 ]),\n",
       " 'mean_score_time': array([0.00186992, 0.00318456, 0.00294328, 0.00632882, 0.00719261,\n",
       "        0.01252627, 0.03034401, 0.05205369, 0.11185217, 0.1069715 ,\n",
       "        0.23668957]),\n",
       " 'mean_test_score': array([0.84653629, 0.8531654 , 0.85117667, 0.85415976, 0.84819357,\n",
       "        0.85415976, 0.85250249, 0.85382831, 0.84852502, 0.85515413,\n",
       "        0.84587338]),\n",
       " 'mean_train_score': array([0.84910665, 0.8530116 , 0.85050654, 0.86001105, 0.85330632,\n",
       "        0.85721127, 0.85201695, 0.86045312, 0.851317  , 0.85625345,\n",
       "        0.84726469]),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[5, 10, 15, 30, 50, 100, 250, 500, 750, 1000, 2000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'hidden_layer_sizes': 5},\n",
       "  {'hidden_layer_sizes': 10},\n",
       "  {'hidden_layer_sizes': 15},\n",
       "  {'hidden_layer_sizes': 30},\n",
       "  {'hidden_layer_sizes': 50},\n",
       "  {'hidden_layer_sizes': 100},\n",
       "  {'hidden_layer_sizes': 250},\n",
       "  {'hidden_layer_sizes': 500},\n",
       "  {'hidden_layer_sizes': 750},\n",
       "  {'hidden_layer_sizes': 1000},\n",
       "  {'hidden_layer_sizes': 2000}],\n",
       " 'rank_test_score': array([10,  5,  7,  2,  9,  2,  6,  4,  8,  1, 11], dtype=int32),\n",
       " 'split0_test_score': array([0.84653629, 0.8531654 , 0.85117667, 0.85415976, 0.84819357,\n",
       "        0.85415976, 0.85250249, 0.85382831, 0.84852502, 0.85515413,\n",
       "        0.84587338]),\n",
       " 'split0_train_score': array([0.84910665, 0.8530116 , 0.85050654, 0.86001105, 0.85330632,\n",
       "        0.85721127, 0.85201695, 0.86045312, 0.851317  , 0.85625345,\n",
       "        0.84726469]),\n",
       " 'std_fit_time': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'std_score_time': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'std_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'std_train_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83074369189907038"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gs.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A teraz tak jak się powinno - na wystandaryzowanych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=None, test_size=0.15, train_size=None),\n",
       "       error_score='accuracy',\n",
       "       estimator=MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.15,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'hidden_layer_sizes': [5, 10, 15, 30, 50, 100, 250, 500, 750, 1000, 2000, 3000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"hidden_layer_sizes\": [(5),(10),(15),(30),(50),(100),(250),(500),(750),(1000),(2000),(3000)]}\n",
    "\n",
    "nnet = MLPClassifier(activation=\"tanh\",early_stopping=True,validation_fraction=0.15,max_iter=1000)\n",
    "gs = GridSearchCV(cv=ShuffleSplit(n_splits=1,test_size=0.15),error_score=\"accuracy\",estimator=nnet,param_grid=params)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.84597, std: 0.00000, params: {'hidden_layer_sizes': 5},\n",
       " mean: 0.84906, std: 0.00000, params: {'hidden_layer_sizes': 10},\n",
       " mean: 0.84729, std: 0.00000, params: {'hidden_layer_sizes': 15},\n",
       " mean: 0.84729, std: 0.00000, params: {'hidden_layer_sizes': 30},\n",
       " mean: 0.84729, std: 0.00000, params: {'hidden_layer_sizes': 50},\n",
       " mean: 0.84729, std: 0.00000, params: {'hidden_layer_sizes': 100},\n",
       " mean: 0.84906, std: 0.00000, params: {'hidden_layer_sizes': 250},\n",
       " mean: 0.84530, std: 0.00000, params: {'hidden_layer_sizes': 500},\n",
       " mean: 0.84619, std: 0.00000, params: {'hidden_layer_sizes': 750},\n",
       " mean: 0.84685, std: 0.00000, params: {'hidden_layer_sizes': 1000},\n",
       " mean: 0.83823, std: 0.00000, params: {'hidden_layer_sizes': 2000},\n",
       " mean: 0.84884, std: 0.00000, params: {'hidden_layer_sizes': 3000}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84588313413014604"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gs.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X.shape[1],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(50,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,471\n",
      "Trainable params: 6,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.4634 - acc: 0.7763\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/50\n",
      "514/514 [==============================] - 0s 134us/step - loss: 0.4605 - acc: 0.7704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/50\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4608 - acc: 0.7665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/50\n",
      "514/514 [==============================] - 0s 123us/step - loss: 0.4595 - acc: 0.7704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/50\n",
      "514/514 [==============================] - 0s 136us/step - loss: 0.4605 - acc: 0.7724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/50\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.4607 - acc: 0.7704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/50\n",
      "514/514 [==============================] - 0s 82us/step - loss: 0.4592 - acc: 0.7704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/50\n",
      "514/514 [==============================] - 0s 135us/step - loss: 0.4599 - acc: 0.7724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/50\n",
      "514/514 [==============================] - 0s 86us/step - loss: 0.4606 - acc: 0.7763\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/50\n",
      "514/514 [==============================] - 0s 134us/step - loss: 0.4589 - acc: 0.7743\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/50\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.4584 - acc: 0.7724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/50\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.4584 - acc: 0.7704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/50\n",
      "514/514 [==============================] - 0s 74us/step - loss: 0.4602 - acc: 0.7724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/50\n",
      "514/514 [==============================] - 0s 78us/step - loss: 0.4578 - acc: 0.7724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/50\n",
      "514/514 [==============================] - 0s 128us/step - loss: 0.4588 - acc: 0.7685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/50\n",
      "514/514 [==============================] - 0s 120us/step - loss: 0.4578 - acc: 0.7743\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/50\n",
      "514/514 [==============================] - 0s 78us/step - loss: 0.4577 - acc: 0.7704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/50\n",
      "514/514 [==============================] - 0s 70us/step - loss: 0.4582 - acc: 0.7724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/50\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.4626 - acc: 0.7743\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/50\n",
      "514/514 [==============================] - 0s 129us/step - loss: 0.4565 - acc: 0.7782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4fd58134a8>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=32,epochs=50,initial_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05601134],\n",
       "       [0.7725957 ],\n",
       "       [0.73465014],\n",
       "       [0.08275977],\n",
       "       [0.5122008 ],\n",
       "       [0.5686697 ],\n",
       "       [0.06430076],\n",
       "       [0.35539806],\n",
       "       [0.78452116],\n",
       "       [0.10250247],\n",
       "       [0.7802958 ],\n",
       "       [0.06215364],\n",
       "       [0.7513312 ],\n",
       "       [0.77202237],\n",
       "       [0.5170231 ],\n",
       "       [0.12746552],\n",
       "       [0.25372684],\n",
       "       [0.18942524],\n",
       "       [0.08372889],\n",
       "       [0.26982772],\n",
       "       [0.48560315],\n",
       "       [0.22771391],\n",
       "       [0.7478473 ],\n",
       "       [0.6298481 ],\n",
       "       [0.13611597],\n",
       "       [0.11709224],\n",
       "       [0.05723199],\n",
       "       [0.5633265 ],\n",
       "       [0.19304739],\n",
       "       [0.39233786],\n",
       "       [0.5333742 ],\n",
       "       [0.28081065],\n",
       "       [0.11159143],\n",
       "       [0.6915605 ],\n",
       "       [0.03773841],\n",
       "       [0.11457501],\n",
       "       [0.40569267],\n",
       "       [0.162352  ],\n",
       "       [0.71364725],\n",
       "       [0.73424137],\n",
       "       [0.7016517 ],\n",
       "       [0.6973858 ],\n",
       "       [0.3823198 ],\n",
       "       [0.03589741],\n",
       "       [0.23712586],\n",
       "       [0.15280889],\n",
       "       [0.64810675],\n",
       "       [0.22710419],\n",
       "       [0.5330056 ],\n",
       "       [0.789008  ],\n",
       "       [0.12906697],\n",
       "       [0.08634376],\n",
       "       [0.37708348],\n",
       "       [0.23944628],\n",
       "       [0.59701484],\n",
       "       [0.47171882],\n",
       "       [0.16991869],\n",
       "       [0.05887353],\n",
       "       [0.18192597],\n",
       "       [0.27641466],\n",
       "       [0.07321911],\n",
       "       [0.7686569 ],\n",
       "       [0.05957082],\n",
       "       [0.72282535],\n",
       "       [0.62912613],\n",
       "       [0.6224674 ],\n",
       "       [0.35107195],\n",
       "       [0.6431007 ],\n",
       "       [0.7797769 ],\n",
       "       [0.5752188 ],\n",
       "       [0.7839817 ],\n",
       "       [0.733469  ],\n",
       "       [0.13289395],\n",
       "       [0.26132354],\n",
       "       [0.6500158 ],\n",
       "       [0.29765892],\n",
       "       [0.18730599],\n",
       "       [0.2016843 ],\n",
       "       [0.04054967],\n",
       "       [0.09078981],\n",
       "       [0.09972318],\n",
       "       [0.42511448],\n",
       "       [0.65219504],\n",
       "       [0.07812969],\n",
       "       [0.25166366],\n",
       "       [0.3167765 ],\n",
       "       [0.79027957],\n",
       "       [0.07781769],\n",
       "       [0.7221439 ],\n",
       "       [0.07121233],\n",
       "       [0.74756926],\n",
       "       [0.35861793],\n",
       "       [0.666556  ],\n",
       "       [0.5856053 ],\n",
       "       [0.4749107 ],\n",
       "       [0.4016074 ],\n",
       "       [0.7348122 ],\n",
       "       [0.03645736],\n",
       "       [0.52005595],\n",
       "       [0.69059795],\n",
       "       [0.524209  ],\n",
       "       [0.13802254],\n",
       "       [0.3944337 ],\n",
       "       [0.36298382],\n",
       "       [0.08519969],\n",
       "       [0.44018587],\n",
       "       [0.07328882],\n",
       "       [0.34878224],\n",
       "       [0.46401027],\n",
       "       [0.7461936 ],\n",
       "       [0.05579034],\n",
       "       [0.7230247 ],\n",
       "       [0.07577983],\n",
       "       [0.08072636],\n",
       "       [0.7300243 ],\n",
       "       [0.3646551 ],\n",
       "       [0.05227097],\n",
       "       [0.35657582],\n",
       "       [0.57592285],\n",
       "       [0.6805222 ],\n",
       "       [0.1192799 ],\n",
       "       [0.03228674],\n",
       "       [0.21045516],\n",
       "       [0.04458167],\n",
       "       [0.04929817],\n",
       "       [0.77548164],\n",
       "       [0.03829954],\n",
       "       [0.65415645],\n",
       "       [0.10649037],\n",
       "       [0.14366914],\n",
       "       [0.05456856],\n",
       "       [0.78853923],\n",
       "       [0.04537395],\n",
       "       [0.08209842],\n",
       "       [0.2054212 ],\n",
       "       [0.04297356],\n",
       "       [0.06255488],\n",
       "       [0.4524177 ],\n",
       "       [0.0407268 ],\n",
       "       [0.79127645],\n",
       "       [0.4569215 ],\n",
       "       [0.2903758 ],\n",
       "       [0.4239828 ],\n",
       "       [0.6595891 ],\n",
       "       [0.28693882],\n",
       "       [0.34764376],\n",
       "       [0.48621008],\n",
       "       [0.04056644],\n",
       "       [0.78111106],\n",
       "       [0.5397673 ],\n",
       "       [0.05509536],\n",
       "       [0.60421854],\n",
       "       [0.22754507],\n",
       "       [0.0597963 ],\n",
       "       [0.23692317],\n",
       "       [0.11871563],\n",
       "       [0.74014324],\n",
       "       [0.11469712],\n",
       "       [0.40332285],\n",
       "       [0.10942918],\n",
       "       [0.4032759 ],\n",
       "       [0.14368348],\n",
       "       [0.06427807],\n",
       "       [0.04238496],\n",
       "       [0.72736114],\n",
       "       [0.29673284],\n",
       "       [0.57436174],\n",
       "       [0.07229511],\n",
       "       [0.25382915],\n",
       "       [0.78376144],\n",
       "       [0.09676711],\n",
       "       [0.75547874],\n",
       "       [0.7662839 ],\n",
       "       [0.23979759],\n",
       "       [0.45395312],\n",
       "       [0.58666795],\n",
       "       [0.6419843 ],\n",
       "       [0.6140414 ],\n",
       "       [0.6470618 ],\n",
       "       [0.60691136],\n",
       "       [0.6869164 ],\n",
       "       [0.09266633],\n",
       "       [0.0714795 ],\n",
       "       [0.07711081],\n",
       "       [0.38461915],\n",
       "       [0.26360732],\n",
       "       [0.04946489],\n",
       "       [0.03903699],\n",
       "       [0.04024809],\n",
       "       [0.76804465],\n",
       "       [0.50411975],\n",
       "       [0.37024963],\n",
       "       [0.7755101 ],\n",
       "       [0.75375426],\n",
       "       [0.49618596],\n",
       "       [0.42058656],\n",
       "       [0.71723294],\n",
       "       [0.03296151],\n",
       "       [0.04030216],\n",
       "       [0.64668095],\n",
       "       [0.53107476],\n",
       "       [0.6109487 ],\n",
       "       [0.7853121 ],\n",
       "       [0.7196459 ],\n",
       "       [0.52390033],\n",
       "       [0.07136222],\n",
       "       [0.5960943 ],\n",
       "       [0.05707268],\n",
       "       [0.34815338],\n",
       "       [0.03880913],\n",
       "       [0.7012397 ],\n",
       "       [0.74135274],\n",
       "       [0.07408356],\n",
       "       [0.47398332],\n",
       "       [0.39318764],\n",
       "       [0.05367177],\n",
       "       [0.4980818 ],\n",
       "       [0.7893036 ],\n",
       "       [0.04614488],\n",
       "       [0.5224459 ],\n",
       "       [0.03451356],\n",
       "       [0.6468025 ],\n",
       "       [0.7006467 ],\n",
       "       [0.34252167],\n",
       "       [0.42375243],\n",
       "       [0.6856731 ],\n",
       "       [0.25976503],\n",
       "       [0.3634973 ],\n",
       "       [0.77731067],\n",
       "       [0.07099918],\n",
       "       [0.13081856],\n",
       "       [0.7499166 ],\n",
       "       [0.57459307],\n",
       "       [0.11674757],\n",
       "       [0.11232676],\n",
       "       [0.13193847],\n",
       "       [0.03807353],\n",
       "       [0.7831942 ],\n",
       "       [0.7015319 ],\n",
       "       [0.30476347],\n",
       "       [0.69544774],\n",
       "       [0.7293696 ],\n",
       "       [0.25062633],\n",
       "       [0.07606581],\n",
       "       [0.7714265 ],\n",
       "       [0.05628801],\n",
       "       [0.17082138],\n",
       "       [0.2172729 ],\n",
       "       [0.52300006],\n",
       "       [0.05867266],\n",
       "       [0.0407001 ],\n",
       "       [0.7022486 ],\n",
       "       [0.76306653],\n",
       "       [0.76215625]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 420us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4900693109655005, 0.7637795299056946]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `Dense` not found.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "?Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 359 samples, validate on 155 samples\n",
      "Epoch 1/100\n",
      "359/359 [==============================] - 1s 3ms/step - loss: 0.7241 - acc: 0.5877 - val_loss: 0.7396 - val_acc: 0.5419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/100\n",
      "359/359 [==============================] - 0s 94us/step - loss: 0.7150 - acc: 0.5989 - val_loss: 0.7285 - val_acc: 0.5484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/100\n",
      "359/359 [==============================] - 0s 157us/step - loss: 0.7067 - acc: 0.6100 - val_loss: 0.7181 - val_acc: 0.5484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/100\n",
      "359/359 [==============================] - 0s 135us/step - loss: 0.6989 - acc: 0.6100 - val_loss: 0.7089 - val_acc: 0.5548\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/100\n",
      "359/359 [==============================] - 0s 169us/step - loss: 0.6917 - acc: 0.6156 - val_loss: 0.7003 - val_acc: 0.5677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/100\n",
      "359/359 [==============================] - 0s 189us/step - loss: 0.6852 - acc: 0.6100 - val_loss: 0.6924 - val_acc: 0.5677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/100\n",
      "359/359 [==============================] - 0s 87us/step - loss: 0.6785 - acc: 0.6212 - val_loss: 0.6841 - val_acc: 0.5742\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/100\n",
      "359/359 [==============================] - 0s 242us/step - loss: 0.6725 - acc: 0.6240 - val_loss: 0.6758 - val_acc: 0.5742\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/100\n",
      "359/359 [==============================] - 0s 120us/step - loss: 0.6659 - acc: 0.6295 - val_loss: 0.6685 - val_acc: 0.5935\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/100\n",
      "359/359 [==============================] - 0s 194us/step - loss: 0.6599 - acc: 0.6323 - val_loss: 0.6614 - val_acc: 0.6129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/100\n",
      "359/359 [==============================] - 0s 96us/step - loss: 0.6542 - acc: 0.6323 - val_loss: 0.6549 - val_acc: 0.6129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/100\n",
      "359/359 [==============================] - 0s 153us/step - loss: 0.6484 - acc: 0.6295 - val_loss: 0.6476 - val_acc: 0.6194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/100\n",
      "359/359 [==============================] - 0s 119us/step - loss: 0.6431 - acc: 0.6379 - val_loss: 0.6411 - val_acc: 0.6194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/100\n",
      "359/359 [==============================] - 0s 119us/step - loss: 0.6372 - acc: 0.6407 - val_loss: 0.6348 - val_acc: 0.6258\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/100\n",
      "359/359 [==============================] - 0s 189us/step - loss: 0.6316 - acc: 0.6462 - val_loss: 0.6283 - val_acc: 0.6323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/100\n",
      "359/359 [==============================] - 0s 304us/step - loss: 0.6259 - acc: 0.6490 - val_loss: 0.6221 - val_acc: 0.6194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/100\n",
      "359/359 [==============================] - 0s 324us/step - loss: 0.6207 - acc: 0.6490 - val_loss: 0.6155 - val_acc: 0.6129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/100\n",
      "359/359 [==============================] - 0s 260us/step - loss: 0.6152 - acc: 0.6462 - val_loss: 0.6097 - val_acc: 0.6129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/100\n",
      "359/359 [==============================] - 0s 281us/step - loss: 0.6104 - acc: 0.6462 - val_loss: 0.6045 - val_acc: 0.6065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/100\n",
      "359/359 [==============================] - 0s 295us/step - loss: 0.6058 - acc: 0.6462 - val_loss: 0.5995 - val_acc: 0.6065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/100\n",
      "359/359 [==============================] - 0s 284us/step - loss: 0.6011 - acc: 0.6462 - val_loss: 0.5948 - val_acc: 0.6000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/100\n",
      "359/359 [==============================] - 0s 243us/step - loss: 0.5968 - acc: 0.6546 - val_loss: 0.5903 - val_acc: 0.6065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/100\n",
      "359/359 [==============================] - 0s 266us/step - loss: 0.5928 - acc: 0.6518 - val_loss: 0.5856 - val_acc: 0.6000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/100\n",
      "359/359 [==============================] - 0s 246us/step - loss: 0.5888 - acc: 0.6490 - val_loss: 0.5814 - val_acc: 0.6129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/100\n",
      "359/359 [==============================] - 0s 170us/step - loss: 0.5846 - acc: 0.6490 - val_loss: 0.5771 - val_acc: 0.6129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/100\n",
      "359/359 [==============================] - 0s 185us/step - loss: 0.5810 - acc: 0.6490 - val_loss: 0.5727 - val_acc: 0.6129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/100\n",
      "359/359 [==============================] - 0s 181us/step - loss: 0.5773 - acc: 0.6490 - val_loss: 0.5691 - val_acc: 0.6194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/100\n",
      "359/359 [==============================] - 0s 133us/step - loss: 0.5735 - acc: 0.6518 - val_loss: 0.5652 - val_acc: 0.6194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/100\n",
      "359/359 [==============================] - 0s 228us/step - loss: 0.5694 - acc: 0.6546 - val_loss: 0.5619 - val_acc: 0.6258\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/100\n",
      "359/359 [==============================] - 0s 242us/step - loss: 0.5655 - acc: 0.6602 - val_loss: 0.5580 - val_acc: 0.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/100\n",
      "359/359 [==============================] - 0s 189us/step - loss: 0.5616 - acc: 0.6602 - val_loss: 0.5540 - val_acc: 0.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/100\n",
      "359/359 [==============================] - 0s 153us/step - loss: 0.5579 - acc: 0.6630 - val_loss: 0.5503 - val_acc: 0.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/100\n",
      "359/359 [==============================] - 0s 119us/step - loss: 0.5541 - acc: 0.6657 - val_loss: 0.5472 - val_acc: 0.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/100\n",
      "359/359 [==============================] - 0s 152us/step - loss: 0.5508 - acc: 0.6657 - val_loss: 0.5442 - val_acc: 0.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/100\n",
      "359/359 [==============================] - 0s 146us/step - loss: 0.5475 - acc: 0.6741 - val_loss: 0.5411 - val_acc: 0.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/100\n",
      "359/359 [==============================] - 0s 214us/step - loss: 0.5442 - acc: 0.6797 - val_loss: 0.5381 - val_acc: 0.6452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/100\n",
      "359/359 [==============================] - 0s 139us/step - loss: 0.5408 - acc: 0.6797 - val_loss: 0.5353 - val_acc: 0.6516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/100\n",
      "359/359 [==============================] - 0s 131us/step - loss: 0.5376 - acc: 0.6825 - val_loss: 0.5328 - val_acc: 0.6645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/100\n",
      "359/359 [==============================] - 0s 181us/step - loss: 0.5342 - acc: 0.6852 - val_loss: 0.5300 - val_acc: 0.6710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/100\n",
      "359/359 [==============================] - 0s 213us/step - loss: 0.5311 - acc: 0.6936 - val_loss: 0.5278 - val_acc: 0.6774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/100\n",
      "359/359 [==============================] - 0s 123us/step - loss: 0.5281 - acc: 0.6992 - val_loss: 0.5260 - val_acc: 0.6839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/100\n",
      "359/359 [==============================] - 0s 132us/step - loss: 0.5253 - acc: 0.7019 - val_loss: 0.5240 - val_acc: 0.6968\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/100\n",
      "359/359 [==============================] - 0s 157us/step - loss: 0.5224 - acc: 0.7075 - val_loss: 0.5218 - val_acc: 0.7032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/100\n",
      "359/359 [==============================] - 0s 119us/step - loss: 0.5196 - acc: 0.7047 - val_loss: 0.5192 - val_acc: 0.7032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/100\n",
      "359/359 [==============================] - 0s 125us/step - loss: 0.5162 - acc: 0.7047 - val_loss: 0.5170 - val_acc: 0.7097\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/100\n",
      "359/359 [==============================] - 0s 95us/step - loss: 0.5134 - acc: 0.7075 - val_loss: 0.5152 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/100\n",
      "359/359 [==============================] - 0s 214us/step - loss: 0.5105 - acc: 0.7131 - val_loss: 0.5134 - val_acc: 0.7097\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/100\n",
      "359/359 [==============================] - 0s 241us/step - loss: 0.5079 - acc: 0.7187 - val_loss: 0.5115 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/100\n",
      "359/359 [==============================] - 0s 196us/step - loss: 0.5054 - acc: 0.7270 - val_loss: 0.5100 - val_acc: 0.7226\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/100\n",
      "359/359 [==============================] - 0s 126us/step - loss: 0.5027 - acc: 0.7326 - val_loss: 0.5084 - val_acc: 0.7226\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 51/100\n",
      "359/359 [==============================] - 0s 107us/step - loss: 0.5002 - acc: 0.7298 - val_loss: 0.5068 - val_acc: 0.7226\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 52/100\n",
      "359/359 [==============================] - 0s 212us/step - loss: 0.4976 - acc: 0.7270 - val_loss: 0.5054 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 53/100\n",
      "359/359 [==============================] - 0s 169us/step - loss: 0.4952 - acc: 0.7270 - val_loss: 0.5039 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 54/100\n",
      "359/359 [==============================] - 0s 280us/step - loss: 0.4928 - acc: 0.7298 - val_loss: 0.5024 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 55/100\n",
      "359/359 [==============================] - 0s 163us/step - loss: 0.4905 - acc: 0.7326 - val_loss: 0.5012 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 56/100\n",
      "359/359 [==============================] - 0s 234us/step - loss: 0.4884 - acc: 0.7354 - val_loss: 0.5006 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 57/100\n",
      "359/359 [==============================] - 0s 203us/step - loss: 0.4866 - acc: 0.7354 - val_loss: 0.4998 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 58/100\n",
      "359/359 [==============================] - 0s 145us/step - loss: 0.4846 - acc: 0.7354 - val_loss: 0.4987 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 59/100\n",
      "359/359 [==============================] - 0s 173us/step - loss: 0.4826 - acc: 0.7354 - val_loss: 0.4979 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 60/100\n",
      "359/359 [==============================] - 0s 187us/step - loss: 0.4806 - acc: 0.7354 - val_loss: 0.4971 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 61/100\n",
      "359/359 [==============================] - 0s 191us/step - loss: 0.4788 - acc: 0.7354 - val_loss: 0.4965 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 62/100\n",
      "359/359 [==============================] - 0s 320us/step - loss: 0.4772 - acc: 0.7382 - val_loss: 0.4958 - val_acc: 0.7161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 63/100\n",
      "359/359 [==============================] - 0s 144us/step - loss: 0.4754 - acc: 0.7437 - val_loss: 0.4952 - val_acc: 0.7226\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 64/100\n",
      "359/359 [==============================] - 0s 219us/step - loss: 0.4738 - acc: 0.7437 - val_loss: 0.4947 - val_acc: 0.7290\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 65/100\n",
      "359/359 [==============================] - 0s 280us/step - loss: 0.4721 - acc: 0.7437 - val_loss: 0.4942 - val_acc: 0.7290\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 66/100\n",
      "359/359 [==============================] - 0s 294us/step - loss: 0.4704 - acc: 0.7437 - val_loss: 0.4936 - val_acc: 0.7355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 67/100\n",
      "359/359 [==============================] - 0s 202us/step - loss: 0.4688 - acc: 0.7437 - val_loss: 0.4934 - val_acc: 0.7355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 68/100\n",
      "359/359 [==============================] - 0s 148us/step - loss: 0.4673 - acc: 0.7465 - val_loss: 0.4928 - val_acc: 0.7355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 69/100\n",
      "359/359 [==============================] - 0s 256us/step - loss: 0.4659 - acc: 0.7493 - val_loss: 0.4926 - val_acc: 0.7419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 70/100\n",
      "359/359 [==============================] - 0s 309us/step - loss: 0.4641 - acc: 0.7521 - val_loss: 0.4923 - val_acc: 0.7419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 71/100\n",
      "359/359 [==============================] - 0s 135us/step - loss: 0.4627 - acc: 0.7521 - val_loss: 0.4920 - val_acc: 0.7419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 72/100\n",
      "359/359 [==============================] - 0s 224us/step - loss: 0.4614 - acc: 0.7521 - val_loss: 0.4920 - val_acc: 0.7419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 73/100\n",
      "359/359 [==============================] - 0s 234us/step - loss: 0.4600 - acc: 0.7521 - val_loss: 0.4917 - val_acc: 0.7419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 74/100\n",
      "359/359 [==============================] - 0s 211us/step - loss: 0.4588 - acc: 0.7577 - val_loss: 0.4914 - val_acc: 0.7484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 75/100\n",
      "359/359 [==============================] - 0s 264us/step - loss: 0.4574 - acc: 0.7577 - val_loss: 0.4915 - val_acc: 0.7419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 76/100\n",
      "359/359 [==============================] - 0s 134us/step - loss: 0.4561 - acc: 0.7577 - val_loss: 0.4915 - val_acc: 0.7484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 77/100\n",
      "359/359 [==============================] - ETA: 0s - loss: 0.4306 - acc: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 0s 144us/step - loss: 0.4551 - acc: 0.7604 - val_loss: 0.4915 - val_acc: 0.7548\n",
      "254/254 [==============================] - 0s 75us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5270465971447351, 0.712598427074162]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(1))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.add(Dropout(1))\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "save_best_model = ModelCheckpoint(\"wagi_best.h5py\",save_best_only=True)\n",
    "\n",
    "model.fit(X_train,y_train, \n",
    "          batch_size=32, \n",
    "          validation_split=0.3,\n",
    "          epochs=100,\n",
    "          callbacks=[early_stopping,save_best_model])\n",
    "\n",
    "\n",
    "model.load_weights(\"wagi_best.h5py\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cwiczenie\n",
    "\n",
    "Zaimplementuj funkcję `construct_mlp(layer_sizes, input_shape, add_dropout, dropout_rate, compile=False)`, która zwraca kerasowy model, gdzie:\n",
    "- `layer_sizes` - krotka rozmiarow kolejnych warstw dense,\n",
    "- `input_shape` - ksztalt danych wejsciowych\n",
    "- `add_dropout` - jeśli `True`, to po każdej warstwie dense w sieci umieszcamy dropout\n",
    "- `dropout_rate` - stopien ewentualnego dropoutu\n",
    "- `compile` - jeśli `True`, to zwracamy skompilowany model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_mlp(layer_sizes, input_shape, add_dropout, dropout_rate, compile=False):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_sizes[0], activation='relu', input_shape=(input_shape,)))\n",
    "    for ls in layer_sizes[1:]:\n",
    "        if add_dropout:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(ls, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if compile:\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Uwaga\n",
    "\n",
    "W różnych materiałach możemy sie spotkać z takim kodem. \n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Takie coś nie ma prawa pojawić się w poprawnym modelowaniu, bo:\n",
    "\n",
    "1. W czasie uczenia wykorzystujemy zbiór testowy (jako walidacyjny) - nie daje to rzetelnej oceny jakości modelu.\n",
    "2. Liczba epok jest ustalona.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='train',categories=['sci.crypt',\n",
    " 'sci.electronics'])\n",
    "\n",
    "X = newsgroups.data\n",
    "y = newsgroups.target\n",
    "\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(y)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_content(mail):    \n",
    "    # wyciagniecie tresci maila   \n",
    "    return mail[mail.find(\"\\n\\n\"):]\n",
    "\n",
    "def extract_subject(mail):\n",
    "    return re.findall(r'Subject:(.+)',mail)[0]\n",
    "\n",
    "\n",
    "def stem_helper(word,stemmer):\n",
    "    try:\n",
    "        y = stemmer.stem(word)\n",
    "    except:\n",
    "        y = word\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(x, stemmer = nltk.PorterStemmer()):   \n",
    "    \"\"\"\n",
    "    x - jeden mail\n",
    "    \"\"\"    \n",
    " \n",
    "    #tokenizacja - rozbicie na liste tokenow\n",
    "    x_t = nltk.word_tokenize(x)    \n",
    "    # usuwanie znakow interpunkcyjnych\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    x_t = [word.translate(translator) for word in x_t]    \n",
    "    # zamina liter male\n",
    "    x_t = [word.lower() for word in x_t]    \n",
    "    # usuwanie zbednych tokenow\n",
    "    x_t = [w for w in x_t if w not in nltk.corpus.stopwords.words(\"english\")+[\"nt\"]]    \n",
    "    # stemming\n",
    "    x_t = [stem_helper(word,stemmer) for word in x_t]    \n",
    "    # sklejenie do napisu\n",
    "    x_new = ' '.join(x_t)    \n",
    "    return x_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_c = [clean_text(extract_content(x)) for x in X]\n",
    "X_s = [clean_text(extract_subject(x)) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\"subject\":X_s, \"content\":X_c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_c,y,test_size=400)\n",
    "#bierzemy tylko tresc - bez tytulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv =CountVectorizer(max_features=2000)\n",
    "\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "X_train_transformed = cv.transform(X_train).todense()\n",
    "X_test_transformed = cv.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 2000), (400, 2))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 550 samples, validate on 236 samples\n",
      "Epoch 1/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 13.2234 - categorical_accuracy: 0.6564 - val_loss: 7.0824 - val_categorical_accuracy: 0.9110\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/100\n",
      "550/550 [==============================] - 0s 499us/step - loss: 4.4101 - categorical_accuracy: 0.9236 - val_loss: 2.1765 - val_categorical_accuracy: 0.9449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/100\n",
      "550/550 [==============================] - 0s 597us/step - loss: 1.3475 - categorical_accuracy: 0.9636 - val_loss: 0.7864 - val_categorical_accuracy: 0.9534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/100\n",
      "550/550 [==============================] - 0s 579us/step - loss: 0.5497 - categorical_accuracy: 0.9836 - val_loss: 0.4621 - val_categorical_accuracy: 0.9534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/100\n",
      "550/550 [==============================] - 0s 395us/step - loss: 0.3622 - categorical_accuracy: 0.9891 - val_loss: 0.3791 - val_categorical_accuracy: 0.9534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/100\n",
      "550/550 [==============================] - 0s 296us/step - loss: 0.3097 - categorical_accuracy: 0.9873 - val_loss: 0.3466 - val_categorical_accuracy: 0.9449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/100\n",
      "550/550 [==============================] - 0s 428us/step - loss: 0.2901 - categorical_accuracy: 0.9945 - val_loss: 0.3502 - val_categorical_accuracy: 0.9449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/100\n",
      "550/550 [==============================] - 0s 516us/step - loss: 0.2701 - categorical_accuracy: 0.9891 - val_loss: 0.3271 - val_categorical_accuracy: 0.9449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/100\n",
      "550/550 [==============================] - 0s 502us/step - loss: 0.2470 - categorical_accuracy: 0.9855 - val_loss: 0.3132 - val_categorical_accuracy: 0.9407\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/100\n",
      "550/550 [==============================] - 0s 415us/step - loss: 0.2428 - categorical_accuracy: 0.9855 - val_loss: 0.3059 - val_categorical_accuracy: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/100\n",
      "550/550 [==============================] - 0s 422us/step - loss: 0.2314 - categorical_accuracy: 0.9855 - val_loss: 0.3013 - val_categorical_accuracy: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/100\n",
      "550/550 [==============================] - 0s 487us/step - loss: 0.2252 - categorical_accuracy: 0.9873 - val_loss: 0.2985 - val_categorical_accuracy: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/100\n",
      "550/550 [==============================] - 0s 519us/step - loss: 0.2228 - categorical_accuracy: 0.9945 - val_loss: 0.2887 - val_categorical_accuracy: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/100\n",
      "550/550 [==============================] - 0s 486us/step - loss: 0.2184 - categorical_accuracy: 0.9873 - val_loss: 0.2894 - val_categorical_accuracy: 0.9407\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/100\n",
      "550/550 [==============================] - 0s 417us/step - loss: 0.2311 - categorical_accuracy: 0.9818 - val_loss: 0.2977 - val_categorical_accuracy: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/100\n",
      "550/550 [==============================] - 0s 450us/step - loss: 0.2185 - categorical_accuracy: 0.9909 - val_loss: 0.2918 - val_categorical_accuracy: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "400/400 [==============================] - 0s 105us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3016233968734741, 0.935]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"relu\",input_shape=(X_train_transformed.shape[1],),kernel_regularizer=l2(0.1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "save_best_model = ModelCheckpoint(\"wagi_best.h5py\",save_best_only=True)\n",
    "\n",
    "model.fit(X_train_transformed,y_train, \n",
    "          batch_size=32, \n",
    "          validation_split=0.3,\n",
    "          epochs=100,\n",
    "          callbacks=[early_stopping,save_best_model])\n",
    "\n",
    "\n",
    "model.load_weights(\"wagi_best.h5py\")\n",
    "model.evaluate(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
